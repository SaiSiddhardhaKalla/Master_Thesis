{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometry& Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run-time (Void this secion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sid/Library/CloudStorage/OneDrive-DeakinUniversity/Git/Master_Thesis/05_Geometry.ipynb Cell 3\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sid/Library/CloudStorage/OneDrive-DeakinUniversity/Git/Master_Thesis/05_Geometry.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Load state boundary shapefile and CSV with village points\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sid/Library/CloudStorage/OneDrive-DeakinUniversity/Git/Master_Thesis/05_Geometry.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m state_boundary \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39mread_file(\u001b[39m'\u001b[39m\u001b[39m/Users/sid/Library/CloudStorage/OneDrive-DeakinUniversity/UDocs - D/DataSets/INDIAN-SHAPEFILES-master/State Boundary/KARNATAKA_STATE.geojson\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sid/Library/CloudStorage/OneDrive-DeakinUniversity/Git/Master_Thesis/05_Geometry.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m villages \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39mread_file(\u001b[39m'\u001b[39m\u001b[39m/Users/sid/Library/CloudStorage/OneDrive-DeakinUniversity/UDocs - D/DataSets/MA/MA Data -  All India All_State/29.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sid/Library/CloudStorage/OneDrive-DeakinUniversity/Git/Master_Thesis/05_Geometry.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(villages))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sid/Library/CloudStorage/OneDrive-DeakinUniversity/Git/Master_Thesis/05_Geometry.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Load the GeoJSON file with urban city points\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/geopandas/io/file.py:281\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m         path_or_bytes \u001b[39m=\u001b[39m filename\n\u001b[0;32m--> 281\u001b[0m     \u001b[39mreturn\u001b[39;00m _read_file_fiona(\n\u001b[1;32m    282\u001b[0m         path_or_bytes, from_bytes, bbox\u001b[39m=\u001b[39mbbox, mask\u001b[39m=\u001b[39mmask, rows\u001b[39m=\u001b[39mrows, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    283\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munknown engine \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mengine\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/geopandas/io/file.py:379\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[1;32m    376\u001b[0m         [record[\u001b[39m\"\u001b[39m\u001b[39mproperties\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m record \u001b[39min\u001b[39;00m f_filt], columns\u001b[39m=\u001b[39mcolumns\n\u001b[1;32m    377\u001b[0m     )\n\u001b[1;32m    378\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     df \u001b[39m=\u001b[39m GeoDataFrame\u001b[39m.\u001b[39mfrom_features(\n\u001b[1;32m    380\u001b[0m         f_filt, crs\u001b[39m=\u001b[39mcrs, columns\u001b[39m=\u001b[39mcolumns \u001b[39m+\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    381\u001b[0m     )\n\u001b[1;32m    382\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m datetime_fields:\n\u001b[1;32m    383\u001b[0m     as_dt \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df[k], errors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/geopandas/geodataframe.py:638\u001b[0m, in \u001b[0;36mGeoDataFrame.from_features\u001b[0;34m(cls, features, crs, columns)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m features_lst:\n\u001b[1;32m    636\u001b[0m     \u001b[39m# load geometry\u001b[39;00m\n\u001b[1;32m    637\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(feature, \u001b[39m\"\u001b[39m\u001b[39m__geo_interface__\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 638\u001b[0m         feature \u001b[39m=\u001b[39m feature\u001b[39m.\u001b[39m__geo_interface__\n\u001b[1;32m    639\u001b[0m     row \u001b[39m=\u001b[39m {\n\u001b[1;32m    640\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m\"\u001b[39m: shape(feature[\u001b[39m\"\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39mif\u001b[39;00m feature[\u001b[39m\"\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    641\u001b[0m     }\n\u001b[1;32m    642\u001b[0m     \u001b[39m# load properties\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/fiona/model.py:367\u001b[0m, in \u001b[0;36mFeature.__geo_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__geo_interface__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m ObjectEncoder()\u001b[39m.\u001b[39mdefault(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/fiona/model.py:395\u001b[0m, in \u001b[0;36mObjectEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    393\u001b[0m         o_dict[\u001b[39m\"\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault(o\u001b[39m.\u001b[39mgeometry)\n\u001b[1;32m    394\u001b[0m     \u001b[39mif\u001b[39;00m o\u001b[39m.\u001b[39mproperties \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 395\u001b[0m         o_dict[\u001b[39m\"\u001b[39m\u001b[39mproperties\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault(o\u001b[39m.\u001b[39mproperties)\n\u001b[1;32m    396\u001b[0m     \u001b[39mreturn\u001b[39;00m o_dict\n\u001b[1;32m    397\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, \u001b[39mbytes\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/fiona/model.py:388\u001b[0m, in \u001b[0;36mObjectEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[1;32m    387\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, (Geometry, Properties)):\n\u001b[0;32m--> 388\u001b[0m         \u001b[39mreturn\u001b[39;00m {k: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault(v) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m o\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m}\n\u001b[1;32m    389\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, Feature):\n\u001b[1;32m    390\u001b[0m         o_dict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(o)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/fiona/model.py:388\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[1;32m    387\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, (Geometry, Properties)):\n\u001b[0;32m--> 388\u001b[0m         \u001b[39mreturn\u001b[39;00m {k: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault(v) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m o\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m}\n\u001b[1;32m    389\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, Feature):\n\u001b[1;32m    390\u001b[0m         o_dict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(o)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/fiona/model.py:386\u001b[0m, in \u001b[0;36mObjectEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mObjectEncoder\u001b[39;00m(JSONEncoder):\n\u001b[1;32m    384\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Encodes Geometry, Feature, and Properties.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[1;32m    387\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, (Geometry, Properties)):\n\u001b[1;32m    388\u001b[0m             \u001b[39mreturn\u001b[39;00m {k: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault(v) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m o\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "# Load state boundary shapefile and CSV with village points\n",
    "state_boundary = gpd.read_file('/Users/sid/Library/CloudStorage/OneDrive-DeakinUniversity/UDocs - D/DataSets/INDIAN-SHAPEFILES-master/State Boundary/KARNATAKA_STATE.geojson')\n",
    "villages = gpd.read_file('/Users/sid/Library/CloudStorage/OneDrive-DeakinUniversity/UDocs - D/DataSets/MA/MA Data -  All India All_State/29.csv')\n",
    "print(len(villages))\n",
    "\n",
    "# Load the GeoJSON file with urban city points\n",
    "geojson_file = '//Users/sid/Library/CloudStorage/OneDrive-DeakinUniversity/UDocs - D/DataSets/INDIAN-SHAPEFILES-master/Subdist_hq/KARNATAKA Sub District Hq.geojson'\n",
    "urban_cities = gpd.read_file(geojson_file)\n",
    "\n",
    "# Ensure the index of urban_cities is consistent and numeric\n",
    "urban_cities.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "def create_geometry(row):\n",
    "    try:\n",
    "        longitude = float(row['village_longitude'])\n",
    "        latitude = float(row['village_latitude'])\n",
    "        return Point(longitude, latitude)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "villages['geometry'] = villages.apply(create_geometry, axis=1)\n",
    "\n",
    "# Perform spatial join\n",
    "joined = gpd.sjoin(villages, state_boundary, how='left', op='within')\n",
    "\n",
    "# Filter and replace points outside the state boundary\n",
    "def replace_latitude(row):\n",
    "    if row['index_right'] >= 0:\n",
    "        return row['village_latitude']\n",
    "    return None\n",
    "\n",
    "def replace_longitude(row):\n",
    "    if row['index_right'] >= 0:\n",
    "        return row['village_longitude']\n",
    "    return None\n",
    "\n",
    "joined['village_latitude'] = joined.apply(replace_latitude, axis=1)\n",
    "joined['village_longitude'] = joined.apply(replace_longitude, axis=1)\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    R = 6371.0  # Radius of the Earth in kilometers\n",
    "    dlon = radians(lon2 - lon1)\n",
    "    dlat = radians(lat2 - lat1)\n",
    "    a = sin(dlat / 2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "def find_nearest_urban_centre(row):\n",
    "    if row['geometry'] is None:\n",
    "        return None, None\n",
    "    \n",
    "    distances = urban_cities.geometry.apply(lambda point: haversine(row['geometry'].x, row['geometry'].y, point.x, point.y))\n",
    "    nearest_city_index = distances.idxmin()\n",
    "    nearest_city_name = urban_cities.loc[nearest_city_index, 'LOC_NAME']\n",
    "    nearest_city_proximity= distances.loc[nearest_city_index]\n",
    "    return nearest_city_name, nearest_city_proximity\n",
    "\n",
    "joined[['nearest_urban_centre', 'nearest_urban_distance']] = joined.apply(find_nearest_urban_centre, axis=1, result_type='expand')\n",
    "\n",
    "# Save the updated CSV with null values for points outside boundary\n",
    "joined.drop(columns=['village_latitude', 'village_longitude','index_right', 'STNAME', 'STCODE11', 'STNAME_SH', 'Shape_Length', 'Shape_Area', 'OBJECTID', 'geometry'], inplace=True)\n",
    "print(len(joined))\n",
    "\n",
    "joined.to_csv('/Users/sid/Desktop/KA.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# Specify the directory containing CSV files\n",
    "folder_path = '/Users/sid/Library/CloudStorage/OneDrive-DeakinUniversity/UDocs - D/DataSets/ma2020/states'\n",
    "\n",
    "# List all CSV files in the folder\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty DataFrame to store concatenated data\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Loop through CSV files and concatenate them\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    data = pd.read_csv(file_path)\n",
    "    all_data = pd.concat([all_data, data], ignore_index=True)\n",
    "\n",
    "# Save the concatenated data to a new CSV file\n",
    "output_file = '/Users/sid/Library/CloudStorage/OneDrive-DeakinUniversity/UDocs - D/DataSets/ma2020/concatenated_data.csv'\n",
    "\n",
    "all_data['nearest_urban_distance'] = np.where(all_data['nearest_urban_distance'] > 250, np.nan, all_data['nearest_urban_distance'])\n",
    "\n",
    "\n",
    "all_data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Concatenated data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "file_path = '/Users/sid/Desktop/ma2020/concatenated_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Select columns from 16 to second last\n",
    "numeric_columns = data.columns[16:-2]\n",
    "\n",
    "# Convert selected columns to numeric, handling errors\n",
    "data[numeric_columns] = data[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop rows with any missing values in selected columns\n",
    "data.dropna(subset=numeric_columns, inplace=True)\n",
    "\n",
    "print(f\"Rows remaining after dropping missing values: {len(data)}\")\n",
    "\n",
    "# Create a new DataFrame for transposed data\n",
    "transposed_data = pd.DataFrame()\n",
    "\n",
    "# Extract columns from 16 to end and transpose them\n",
    "columns_to_transpose = data.columns[16:-2]\n",
    "numeric_columns_to_transpose = [col for col in columns_to_transpose if pd.api.types.is_numeric_dtype(data[col])]\n",
    "\n",
    "transposed_data['Variable'] = numeric_columns_to_transpose\n",
    "transposed_data['Range'] = transposed_data['Variable'].apply(lambda col: data[col].max() - data[col].min() if col in data else None)\n",
    "transposed_data['Max'] = transposed_data['Variable'].apply(lambda col: data[col].max() if col in data else None)\n",
    "transposed_data['Min'] = transposed_data['Variable'].apply(lambda col: data[col].min() if col in data else None)\n",
    "transposed_data['Average'] = transposed_data['Variable'].apply(lambda col: data[col].mean() if col in data else None)  # Add Average column\n",
    "transposed_data['Median'] = transposed_data['Variable'].apply(lambda col: data[col].median() if col in data else None)  # Add Median column\n",
    "\n",
    "# Save the summary data to a new CSV file\n",
    "output_transposed_file = '/Users/sid/Desktop/ma2020/summary_data.csv'\n",
    "transposed_data.to_csv(output_transposed_file, index=False)\n",
    "\n",
    "print(f\"Transposed data saved to {output_transposed_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Village area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.ops import transform\n",
    "from functools import partial\n",
    "import pyproj\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Load the shapefile\n",
    "shapefile_path = '/Users/sid/Library/CloudStorage/OneDrive-DeakinUniversity/UDocs - D/DataSets/VIIRS_Monthly_Tiled/2018/tmpif4jtczm.shp'\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Define the geodetic coordinate system (EPSG:4326)\n",
    "geod = pyproj.Geod(ellps='WGS84')\n",
    "\n",
    "def calculate_area(row):\n",
    "    geometry = row['geometry']\n",
    "    if geometry.geom_type == 'Polygon':\n",
    "        polygons = [geometry]\n",
    "    elif geometry.geom_type == 'MultiPolygon':\n",
    "        polygons = geometry.geoms\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "    area = 0.0\n",
    "    for polygon in polygons:\n",
    "        lon, lat = polygon.centroid.x, polygon.centroid.y\n",
    "        vertices = list(polygon.exterior.coords)\n",
    "        for i in range(len(vertices) - 1):\n",
    "            lon1, lat1 = vertices[i]\n",
    "            lon2, lat2 = vertices[i + 1]\n",
    "            _, _, distance = geod.inv(lon1, lat1, lon2, lat2)\n",
    "            area += lat1 * lat2 * distance\n",
    "    return abs(area) / 2.0 / 1e6\n",
    "\n",
    "# Calculate the area in square kilometers\n",
    "gdf['area_sq_km'] = gdf.apply(calculate_area, axis=1)\n",
    "\n",
    "# # Create a new DataFrame with desired columns\n",
    "# new_df = gdf[['attribute_column1', 'attribute_column2', 'area_sq_km']]\n",
    "\n",
    "# # Export the new DataFrame to a CSV file\n",
    "# csv_output_path = 'output.csv'\n",
    "# new_df.to_csv(csv_output_path, index=False)\n",
    "\n",
    "# print(f'CSV file saved at: {csv_output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    'DTCODE11.x': 'DTNAME',\n",
    "    'State code': 'State_code',\n",
    "    'State Name': 'State',\n",
    "    'State cens':'State_census_code',\n",
    "    'District c':'District_census_code', \n",
    "    'District N':'District', \n",
    "    'District_1':'District_code', \n",
    "    'SubDistric':'SubDistric', \n",
    "    'Subdistr_1':'Subdistrict',\n",
    "    'Subdistr_2':'Subdistr_2', \n",
    "    'Village co':'village_code', \n",
    "    'Village Na':'Village', \n",
    "    'Block code':'Block_code', \n",
    "    'Block Name':'Block',\n",
    "}\n",
    "\n",
    "gdf.rename(columns=column_mapping, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = gdf[['DTNAME',\t'State_code', 'State', 'State_census_code', 'District_census_code',\t'District', \n",
    "              'District_code', 'SubDistric', 'Subdistrict', 'Subdistr_2', 'village_code', 'Village', 'Block_code', 'Block', 'area_sq_km']]\n",
    "\n",
    "new_df = new_df.dropna(subset='village_code')\n",
    "new_df = new_df.drop_duplicates(subset='village_code')\n",
    "new_df\n",
    "\n",
    "# # Export the new DataFrame to a CSV file\n",
    "# csv_output_path = '/Users/sid/Library/CloudStorage/OneDrive-DeakinUniversity/UDocs - D/DataSets/ma2020/area.csv'\n",
    "# new_df.to_csv(csv_output_path, index=False)\n",
    "\n",
    "# print(f'CSV file saved at: {csv_output_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
